{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gS1TV7cOYnWM"
   },
   "source": [
    "# Emotion Classification in short texts with BERT\n",
    "\n",
    "Applying BERT to the problem of multiclass text classification. Our dataset consists of written dialogs, messages and short stories. Each dialog utterance/message is labeled with one of the five emotion categories: joy, anger, sadness, fear, neutral. \n",
    "\n",
    "## Workflow: \n",
    "1. Import Data\n",
    "2. Data preprocessing and downloading BERT\n",
    "3. Training and validation\n",
    "4. Saving the model\n",
    "\n",
    "Multiclass text classification with BERT and [ktrain](https://github.com/amaiya/ktrain). Use google colab for a free GPU \n",
    "\n",
    "ðŸ‘‹  **Let's start** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 97
    },
    "colab_type": "code",
    "id": "FYJa3hJiYnWP",
    "outputId": "0f7f0dec-cdf8-48a5-fe4c-fb7695f76856"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import ktrain\n",
    "from ktrain import text\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "33Sa8kVvYnWR"
   },
   "source": [
    "## 1. Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 495
    },
    "colab_type": "code",
    "id": "xGRw5awSX7mZ",
    "outputId": "b0b110b6-a3ed-48a3-e46f-5071475dffde"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of training set: 7934\n",
      "size of validation set: 3393\n",
      "joy        2326\n",
      "sadness    2317\n",
      "anger      2259\n",
      "neutral    2254\n",
      "fear       2171\n",
      "Name: Emotion, dtype: int64\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "data_train = pd.read_csv('data/data_train.csv', encoding='utf-8')\n",
    "data_test = pd.read_csv('data/data_test.csv', encoding='utf-8')\n",
    "\n",
    "X_train = data_train.Text.tolist()\n",
    "X_test = data_test.Text.tolist()\n",
    "\n",
    "y_train = data_train.Emotion.tolist()\n",
    "y_test = data_test.Emotion.tolist()\n",
    "\n",
    "data = data_train.append(data_test, ignore_index=True)\n",
    "\n",
    "class_names = ['joy', 'sadness', 'fear', 'anger', 'neutral']\n",
    "\n",
    "print('size of training set: %s' % (len(data_train['Text'])))\n",
    "print('size of validation set: %s' % (len(data_test['Text'])))\n",
    "print(data.Emotion.value_counts())\n",
    "\n",
    "data.head(10)\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gBxd1kYYYnWU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "encoding = {\n",
    "    'joy': 0,\n",
    "    'sadness': 1,\n",
    "    'fear': 2,\n",
    "    'anger': 3,\n",
    "    'neutral': 4\n",
    "}\n",
    "\n",
    "# Integer values for each class\n",
    "y_train = [encoding[x] for x in y_train]\n",
    "y_test = [encoding[x] for x in y_test]\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pcuN5eklYnWW"
   },
   "source": [
    "## 2. Data preprocessing\n",
    "\n",
    "* The text must be preprocessed in a specific way for use with BERT. This is accomplished by setting preprocess_mode to â€˜bertâ€™. The BERT model and vocabulary will be automatically downloaded\n",
    "\n",
    "* BERT can handle a maximum length of 512, but let's use less to reduce memory and improve speed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "colab_type": "code",
    "id": "IQnZnKQmZA3U",
    "outputId": "38dcedee-706f-4d32-e578-976b8b55826c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing train...\n",
      "language: en\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "done."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Multi-Label? False\n",
      "preprocessing test...\n",
      "language: en\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "done."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task: text classification\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "(x_train,  y_train), (x_test, y_test), preproc = text.texts_from_array(x_train=X_train, y_train=y_train,\n",
    "                                                                       x_test=X_test, y_test=y_test,\n",
    "                                                                       class_names=class_names,\n",
    "                                                                       preprocess_mode='bert',\n",
    "                                                                       maxlen=350, \n",
    "                                                                       max_features=35000)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V4fuvHPnYnWY"
   },
   "source": [
    "## 2. Training and validation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1KwBXM9BYnWZ"
   },
   "source": [
    "Loading the pretrained BERT for text classification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "1cGb2CaOZBNS",
    "outputId": "4d05d637-9692-45e3-8ada-0dab9603480e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Multi-Label? False\n",
      "maxlen is 350\n",
      "done.\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "model = text.text_classifier('bert', train_data=(x_train, y_train), preproc=preproc)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JkgvS2pvYnWb"
   },
   "source": [
    "Wrap it in a Learner object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zu8uv-xKYnWc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "learner = ktrain.get_learner(model, train_data=(x_train, y_train), \n",
    "                             val_data=(x_test, y_test),\n",
    "                             batch_size=6)\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h4YY0JBAYnWd"
   },
   "source": [
    "Train the model. More about tuning learning rates [here](https://github.com/amaiya/ktrain/blob/master/tutorial-02-tuning-learning-rates.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "colab_type": "code",
    "id": "jD-2RpgkZN_n",
    "outputId": "74ab6af9-e127-44b2-bb14-eb23b3ed17d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "begin training using onecycle policy with max lr of 2e-05...\n",
      "Epoch 1/3\n"
     ]
    }
   ],
   "source": [
    "learner.fit_onecycle(2e-5, 3)\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xHhddIieYnWg"
   },
   "source": [
    "Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "colab_type": "code",
    "id": "2s4ao_e2i4ld",
    "outputId": "fd6d79ca-5d3d-41b0-86ff-a8d331e2847d"
   },
   "outputs": [],
   "source": [
    "learner.validate(val_data=(x_test, y_test), class_names=class_names)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MI0nWZlhYnWi"
   },
   "source": [
    "#### Testing with other inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "6eDpFIoXjlE8",
    "outputId": "a59d84b8-ec69-4253-bfa3-7364bb791fb1"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ktrain' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-9ef6a5209926>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredictor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mktrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_predictor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreproc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mpredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ktrain' is not defined"
     ]
    }
   ],
   "source": [
    "predictor = ktrain.get_predictor(learner.model, preproc)\n",
    "predictor.get_classes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "w5KQfwX8xLLu",
    "outputId": "99d2ba47-87ba-4e96-c03f-558746e91ede"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predictor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-371f8979dbc6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'predicted: {} ({:.2f})'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'predictor' is not defined"
     ]
    }
   ],
   "source": [
    "import time \n",
    "\n",
    "message = 'I just broke up with my boyfriend'\n",
    "\n",
    "start_time = time.time() \n",
    "prediction = predictor.predict(message)\n",
    "\n",
    "print('predicted: {} ({:.2f})'.format(prediction, (time.time() - start_time)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rusM_SzpYnWm"
   },
   "source": [
    "## 4. Saving Bert model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YBkGko4Sz2ef"
   },
   "outputs": [],
   "source": [
    "# let's save the predictor for later use\n",
    "predictor.save(\"models/bert_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "predictor = load_model('models/cnn_w2v.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qQo2P03tYnWo"
   },
   "source": [
    "Done! to reload the predictor use: ktrain.load_predictor"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "bert.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
